import streamlit as st
import os
import pandas as pd
from services.azure_clients import get_container_client, setup_openai_client
from services.document_intelligence import list_blobs_by_prefix, extract_job_posting_text, analyze_resume_with_ai
from services.llm_service import evaluate_candidate_fit, extract_score_from_evaluation
from components.chatbot import chat_with_llm
from utils.data_parser import process_certificate_field, process_award_field, process_education_field, process_experience_field

def main():
    st.set_page_config(
        page_title="ì´ë ¥ì„œ ë¶„ì„ ì‹œìŠ¤í…œ",
        page_icon="ğŸ“„",
        layout="wide"
    )
    
    # ìŠ¤í¬ë¡¤ë°” ë„ˆë¹„ ì¡°ì ˆ
    st.markdown("""
    <style>
        ::-webkit-scrollbar {
            width: 12px;
        }
    </style>
    """, unsafe_allow_html=True)
    
    st.title("ğŸ“„ ì´ë ¥ì„œ ë¶„ì„ ì‹œìŠ¤í…œ")
    
    # API í‚¤ ë””ë²„ê·¸ ì •ë³´ í‘œì‹œ
    import os
    from dotenv import load_dotenv
    load_dotenv()
    
    # í™˜ê²½ ë³€ìˆ˜ ìƒíƒœ í™•ì¸
    env_vars = {
        "OPENAI_API_KEY": os.getenv("OPENAI_API_KEY"),
        "AZURE_ENDPOINT": os.getenv("AZURE_ENDPOINT"),
        "OPENAI_API_VERSION": os.getenv("OPENAI_API_VERSION"),
        "OPENAI_API_TYPE": os.getenv("OPENAI_API_TYPE"),
        "AZURE_STORAGE_CONNECTION_STRING": os.getenv("AZURE_STORAGE_CONNECTION_STRING"),
        "DOCUMENT_INTELLIGENCE_ENDPOINT": os.getenv("DOCUMENT_INTELLIGENCE_ENDPOINT"),
        "DOCUMENT_INTELLIGENCE_KEY": os.getenv("DOCUMENT_INTELLIGENCE_KEY")
    }
    
    # ë””ë²„ê·¸ ì •ë³´ í‘œì‹œ (ê°œë°œìš©)
    with st.expander("ğŸ” API í‚¤ ë””ë²„ê·¸ ì •ë³´", expanded=False):
        st.write("**í™˜ê²½ ë³€ìˆ˜ ìƒíƒœ:**")
        for key, value in env_vars.items():
            if value:
                # API í‚¤ëŠ” ë³´ì•ˆì„ ìœ„í•´ ì¼ë¶€ë§Œ í‘œì‹œ
                if "KEY" in key or "CONNECTION_STRING" in key:
                    masked_value = value[:10] + "..." + value[-10:] if len(value) > 20 else "***"
                    st.write(f"- {key}: {masked_value}")
                else:
                    st.write(f"- {key}: {value}")
            else:
                st.write(f"- {key}: âŒ ì„¤ì •ë˜ì§€ ì•ŠìŒ")
        
        # ëˆ„ë½ëœ í•„ìˆ˜ API í‚¤ í™•ì¸
        missing_apis = []
        if not env_vars["OPENAI_API_KEY"]:
            missing_apis.append("Azure OpenAI API í‚¤")
        if not env_vars["AZURE_ENDPOINT"]:
            missing_apis.append("Azure OpenAI ì—”ë“œí¬ì¸íŠ¸")
        if not env_vars["AZURE_STORAGE_CONNECTION_STRING"]:
            missing_apis.append("Azure Storage ì—°ê²° ë¬¸ìì—´")
        if not env_vars["DOCUMENT_INTELLIGENCE_ENDPOINT"]:
            missing_apis.append("Document Intelligence ì—”ë“œí¬ì¸íŠ¸")
        if not env_vars["DOCUMENT_INTELLIGENCE_KEY"]:
            missing_apis.append("Document Intelligence í‚¤")
        
        if missing_apis:
            st.error(f"âŒ ë‹¤ìŒ API í‚¤ê°€ ì„¤ì •ë˜ì§€ ì•Šì•˜ìŠµë‹ˆë‹¤: {', '.join(missing_apis)}")
        else:
            st.success("âœ… ëª¨ë“  í•„ìˆ˜ API í‚¤ê°€ ì„¤ì •ë˜ì—ˆìŠµë‹ˆë‹¤.")
    
    st.markdown("---")
    
    # ì»¨í…Œì´ë„ˆ í´ë¼ì´ì–¸íŠ¸ ê°€ì ¸ì˜¤ê¸°
    container_client = get_container_client()
    
    if not container_client:
        st.error("ì»¨í…Œì´ë„ˆì— ì—°ê²°í•  ìˆ˜ ì—†ìŠµë‹ˆë‹¤.")
        return
    
    # ì±„ìš©ê³µê³  íŒŒì¼ë“¤ ê°€ì ¸ì˜¤ê¸°
    job_files = list_blobs_by_prefix(container_client, "job-posting/")
    
    # ì±„ìš©ê³µê³  ì„ íƒ ë° í‘œì‹œ
    if job_files:
        st.subheader("ğŸ“¢ ì±„ìš©ê³µê³ ")
        selected_job = st.selectbox(
            "ì±„ìš©ê³µê³  íŒŒì¼ ì„ íƒ", 
            job_files, 
            format_func=lambda x: os.path.basename(x),
            help="ë¶„ì„í•  ì±„ìš©ê³µê³ ë¥¼ ì„ íƒí•˜ì„¸ìš”"
        )
        
        if selected_job:
            # ì±„ìš©ê³µê³  í…ìŠ¤íŠ¸ ì¶”ì¶œ
            job_text = extract_job_posting_text(selected_job, container_client)
            
            if job_text:
                with st.expander(f"ğŸ“‹ {os.path.basename(selected_job)} - ì±„ìš©ê³µê³  ë‚´ìš©", expanded=True):
                    st.text_area("ì±„ìš©ê³µê³  ë‚´ìš©", job_text, height=800, disabled=True)
                    
                    # ì±„ìš©ê³µê³  ë‹¤ìš´ë¡œë“œ ë²„íŠ¼
                    blob_client = container_client.get_blob_client(selected_job)
                    st.download_button(
                        label="ğŸ“¥ ì±„ìš©ê³µê³  íŒŒì¼ ë‹¤ìš´ë¡œë“œ",
                        data=blob_client.download_blob().readall(),
                        file_name=os.path.basename(selected_job),
                        mime="application/octet-stream"
                    )
            else:
                st.warning("ì„ íƒí•œ ì±„ìš©ê³µê³ ì—ì„œ í…ìŠ¤íŠ¸ë¥¼ ì¶”ì¶œí•  ìˆ˜ ì—†ìŠµë‹ˆë‹¤.")
    else:
        st.info("ğŸ“¢ ì±„ìš©ê³µê³ ê°€ ì—…ë¡œë“œë˜ì–´ ìˆì§€ ì•ŠìŠµë‹ˆë‹¤.")
    
    st.markdown("---")
    
    # ì„¸ì…˜ ìƒíƒœ ì´ˆê¸°í™”
    if 'analysis_in_progress' not in st.session_state:
        st.session_state.analysis_in_progress = False
    if 'analysis_results' not in st.session_state:
        st.session_state.analysis_results = None
    if 'analysis_completed' not in st.session_state:
        st.session_state.analysis_completed = False
    
    # Resume í´ë”ì˜ íŒŒì¼ë“¤ ê°€ì ¸ì˜¤ê¸°
    try:
        if not container_client:
            st.error("ì»¨í…Œì´ë„ˆ í´ë¼ì´ì–¸íŠ¸ê°€ Noneì…ë‹ˆë‹¤.")
            return
        
        blobs = container_client.list_blobs()
        if blobs is None:
            st.warning("Blob ëª©ë¡ì„ ê°€ì ¸ì˜¬ ìˆ˜ ì—†ìŠµë‹ˆë‹¤.")
            return
        
        blob_list = list(blobs)
        resume_files = [blob for blob in blob_list if 'resume' in blob.name.lower()]
        
        st.info(f"ì´ {len(blob_list)}ê°œì˜ íŒŒì¼ì„ ì°¾ì•˜ê³ , ê·¸ ì¤‘ {len(resume_files)}ê°œì˜ ì´ë ¥ì„œ íŒŒì¼ì´ ìˆìŠµë‹ˆë‹¤.")
        
        if not resume_files:
            st.warning("ğŸ“ Resume í´ë”ì— íŒŒì¼ì´ ì—†ìŠµë‹ˆë‹¤.")
            return
        
        # ë¶„ì„ ì¤‘ì´ ì•„ë‹ ë•Œì™€ ë¶„ì„ ì¤‘ì¼ ë•Œë¥¼ ì™„ì „íˆ ë¶„ë¦¬
        if not st.session_state.analysis_in_progress:
            # ë¶„ì„ ì¤‘ì´ ì•„ë‹ ë•Œë§Œ í‘œì‹œí•  ì»¨í…Œì´ë„ˆ
            with st.container():
                st.subheader(f"ğŸ“‹ Resume í´ë” íŒŒì¼ ëª©ë¡ ({len(resume_files)}ê°œ)")
                
                # ë¶„ì„ ë²„íŠ¼
                if st.button("ğŸš€ ëª¨ë“  ì´ë ¥ì„œ ë¶„ì„ ì‹œì‘", type="primary"):
                    st.session_state.analysis_in_progress = True
                    st.session_state.analysis_completed = False
                    st.session_state.analysis_results = None
                    st.rerun()
                
                # íŒŒì¼ ëª©ë¡ í‘œì‹œ
                st.write("**ğŸ“ ë¶„ì„í•  íŒŒì¼ ëª©ë¡:**")
                for blob in resume_files:
                    st.write(f"- {blob.name}")
        
        # ë¶„ì„ ì¤‘ì¼ ë•Œ - ì™„ì „íˆ ë‹¤ë¥¸ ì»¨í…Œì´ë„ˆ
        if st.session_state.analysis_in_progress:
            # ê¸°ì¡´ ì»¨í…ì¸ ë¥¼ ì§€ìš°ê³  ë¶„ì„ ì§„í–‰ ìƒíƒœë§Œ í‘œì‹œ
            analysis_container = st.empty()
            with analysis_container.container():
                st.info("ë¶„ì„ì„ ì‹œì‘í•©ë‹ˆë‹¤. ì ì‹œë§Œ ê¸°ë‹¤ë ¤ì£¼ì„¸ìš”...")
            
            # ì§„í–‰ë¥  í‘œì‹œ
            progress_bar = st.progress(0)
            status_text = st.empty()
            
            all_results = []
            
            for i, blob in enumerate(resume_files):
                status_text.text(f"ë¶„ì„ ì¤‘: {blob.name} ({i+1}/{len(resume_files)})")
                
                # Document Intelligenceë¡œ ë¶„ì„
                analysis_result = analyze_resume_with_ai(blob.name)
                
                if analysis_result:
                    # ì í•©ì„± í‰ê°€ ê²°ê³¼ë„ í•¨ê»˜ ì €ì¥
                    fitness_evaluation = None
                    fitness_score = None
                    
                    if job_files and selected_job:
                        job_text = extract_job_posting_text(selected_job, container_client)
                        if job_text and analysis_result["documents"] and analysis_result["documents"][0]["fields"]:
                            fields_data = analysis_result["documents"][0]["fields"]
                            target_fields = ["í•™ë ¥ì‚¬í•­", "ê²½ë ¥ì‚¬í•­", "ìê²©ì¦", "ìˆ˜ìƒê²½ë ¥"]
                            resume_fields = {}
                            
                            for field_name in target_fields:
                                if field_name in fields_data:
                                    if field_name == "í•™ë ¥ì‚¬í•­":
                                        # í•™ë ¥ì‚¬í•­ ë°ì´í„°ë¥¼ êµ¬ì¡°í™”ëœ í˜•íƒœë¡œ ë³€í™˜
                                        from services.llm_service import process_education_field
                                        education_data = process_education_field(fields_data[field_name]['content'])
                                        resume_fields[field_name] = education_data
                                    elif field_name == "ê²½ë ¥ì‚¬í•­":
                                        # ê²½ë ¥ì‚¬í•­ ë°ì´í„°ë¥¼ êµ¬ì¡°í™”ëœ í˜•íƒœë¡œ ë³€í™˜
                                        from services.llm_service import process_experience_field
                                        experience_data = process_experience_field(fields_data[field_name]['content'])
                                        resume_fields[field_name] = experience_data
                                    elif field_name == "ìê²©ì¦":
                                        # ìê²©ì¦ ë°ì´í„°ë¥¼ êµ¬ì¡°í™”ëœ í˜•íƒœë¡œ ë³€í™˜
                                        from services.llm_service import process_certificate_field
                                        certificate_data = process_certificate_field(fields_data[field_name]['content'])
                                        resume_fields[field_name] = certificate_data
                                    elif field_name == "ìˆ˜ìƒê²½ë ¥":
                                        # ìˆ˜ìƒê²½ë ¥ ë°ì´í„°ë¥¼ êµ¬ì¡°í™”ëœ í˜•íƒœë¡œ ë³€í™˜
                                        from services.llm_service import process_award_field
                                        award_data = process_award_field(fields_data[field_name]['content'])
                                        resume_fields[field_name] = award_data
                                    else:
                                        resume_fields[field_name] = fields_data[field_name]['content']
                            
                            if resume_fields:
                                # API í‚¤ ìƒíƒœ í™•ì¸
                                import os
                                from dotenv import load_dotenv
                                load_dotenv()
                                
                                openai_key = os.getenv("OPENAI_API_KEY")
                                azure_endpoint = os.getenv("AZURE_ENDPOINT")
                                
                                # API í‚¤ ë””ë²„ê·¸ ì •ë³´ ì¶”ê°€
                                debug_info = f"""
ğŸ” ë””ë²„ê·¸ ì •ë³´:
- OpenAI API í‚¤: {'ì„¤ì •ë¨' if openai_key else 'ì„¤ì •ë˜ì§€ ì•ŠìŒ'}
- Azure ì—”ë“œí¬ì¸íŠ¸: {'ì„¤ì •ë¨' if azure_endpoint else 'ì„¤ì •ë˜ì§€ ì•ŠìŒ'}
- ì´ë ¥ì„œ í•„ë“œ ìˆ˜: {len(resume_fields)}
- ì±„ìš©ê³µê³  ê¸¸ì´: {len(job_text) if job_text else 0}ì
"""
                                
                                success, evaluation_result = evaluate_candidate_fit(job_text, resume_fields)
                                if success:
                                    fitness_evaluation = evaluation_result
                                    fitness_score = extract_score_from_evaluation(evaluation_result)
                                else:
                                    # ì‹¤íŒ¨ ì‹œ ë””ë²„ê·¸ ì •ë³´ í¬í•¨
                                    fitness_evaluation = f"âŒ í‰ê°€ ì‹¤íŒ¨\n{debug_info}\n\nì˜¤ë¥˜: {evaluation_result}"
                                    fitness_score = None
                    
                    all_results.append({
                        "file_name": blob.name,
                        "analysis": analysis_result,
                        "fitness_evaluation": fitness_evaluation,
                        "fitness_score": fitness_score
                    })
                
                # ì§„í–‰ë¥  ì—…ë°ì´íŠ¸
                progress_bar.progress((i + 1) / len(resume_files))
            
            # ë¶„ì„ ì™„ë£Œ
            st.session_state.analysis_results = all_results
            st.session_state.analysis_in_progress = False
            st.session_state.analysis_completed = True
            st.rerun()
        
        # ë¶„ì„ ì™„ë£Œ í›„ ê²°ê³¼ í‘œì‹œ
        if st.session_state.analysis_completed and st.session_state.analysis_results:
            all_results = st.session_state.analysis_results
            
            st.success(f"âœ… {len(all_results)}ê°œ íŒŒì¼ ë¶„ì„ ì™„ë£Œ!")
            
            # ê²°ê³¼ ìš”ì•½
            st.subheader("ğŸ“Š ë¶„ì„ ê²°ê³¼ ìš”ì•½")
            
            summary_data = []
            for result in all_results:
                file_name = result["file_name"]
                analysis = result["analysis"]
                
                # ë¬¸ì„œ ì •ë³´
                doc_count = len(analysis["documents"])
                page_count = len(analysis["pages"])
                table_count = len(analysis["tables"])
                kv_count = len(analysis["key_value_pairs"])
                
                # í•„ë“œ ì •ë³´ (ì²« ë²ˆì§¸ ë¬¸ì„œ ê¸°ì¤€)
                fields = []
                if analysis["documents"]:
                    fields = list(analysis["documents"][0]["fields"].keys())
                
                # ì €ì¥ëœ ì í•©ì„± ì ìˆ˜ ì‚¬ìš©
                fitness_score = result.get("fitness_score")
                
                summary_data.append({
                    "íŒŒì¼ëª…": file_name,
                    "ë¬¸ì„œ ìˆ˜": doc_count,
                    "í˜ì´ì§€ ìˆ˜": page_count,
                    "í…Œì´ë¸” ìˆ˜": table_count,
                    "í‚¤-ê°’ ìŒ ìˆ˜": kv_count,
                    "ì¶”ì¶œëœ í•„ë“œ": ", ".join(fields[:5]) + ("..." if len(fields) > 5 else ""),
                    "ì í•©ì„± ì ìˆ˜": fitness_score if fitness_score is not None else "í‰ê°€ ë¶ˆê°€"
                })
            
            # ì ìˆ˜ ìˆœìœ¼ë¡œ ì •ë ¬ (ì ìˆ˜ê°€ ë†’ì€ ìˆœ)
            df_summary = pd.DataFrame(summary_data)
            # ì í•©ì„± ì ìˆ˜ê°€ ìˆ«ìì¸ ê²½ìš°ë§Œ ì •ë ¬ ê°€ëŠ¥í•˜ë„ë¡ ì²˜ë¦¬
            df_summary['ì •ë ¬ìš©_ì ìˆ˜'] = pd.to_numeric(df_summary['ì í•©ì„± ì ìˆ˜'].replace('í‰ê°€ ë¶ˆê°€', -1), errors='coerce')
            df_summary = df_summary.sort_values('ì •ë ¬ìš©_ì ìˆ˜', ascending=False)
            df_summary = df_summary.drop('ì •ë ¬ìš©_ì ìˆ˜', axis=1)
            
            # ìš”ì•½ í…Œì´ë¸” í‘œì‹œ
            st.dataframe(df_summary, use_container_width=True)
            
            # ìƒì„¸ ê²°ê³¼ í‘œì‹œ
            st.subheader("ğŸ” ìƒì„¸ ë¶„ì„ ê²°ê³¼")
            
            for result in all_results:
                file_name = result["file_name"]
                analysis = result["analysis"]
                
                with st.expander(f"ğŸ“„ {file_name}", expanded=False):
                    # í•„ë“œ ì •ë³´ í‘œì‹œ
                    if analysis["documents"] and analysis["documents"][0]["fields"]:
                        st.write("**ğŸ·ï¸ ì¶”ì¶œëœ í•„ë“œ:**")
                        fields = analysis["documents"][0]["fields"]
                        
                        # í•„ë“œ ë°ì´í„°ë¥¼ í…Œì´ë¸” í˜•íƒœë¡œ ì¤€ë¹„
                        field_data = []
                        for field_name, field_info in fields.items():
                            # í•™ë ¥ì‚¬í•­ í•„ë“œì¸ ê²½ìš° êµ¬ì¡°í™”ëœ í˜•íƒœë¡œ í‘œì‹œ
                            if field_name == "í•™ë ¥ì‚¬í•­":
                                from services.llm_service import process_education_field
                                education_data = process_education_field(field_info['content'])
                                if education_data:
                                    # í•™ë ¥ì‚¬í•­ ë°ì´í„°ë¥¼ JSON í˜•íƒœë¡œ í‘œì‹œ
                                    import json
                                    education_json = json.dumps(education_data, ensure_ascii=False, indent=2)
                                    field_data.append({
                                        "í•„ë“œëª…": field_name,
                                        "íƒ€ì…": field_info['type'],
                                        "ê°’": education_json,
                                        "ì‹ ë¢°ë„": f"{field_info['confidence']:.2f}"
                                    })
                                else:
                                    field_data.append({
                                        "í•„ë“œëª…": field_name,
                                        "íƒ€ì…": field_info['type'],
                                        "ê°’": "í•™ë ¥ì‚¬í•­ ì •ë³´ ì—†ìŒ",
                                        "ì‹ ë¢°ë„": f"{field_info['confidence']:.2f}"
                                    })
                            elif field_name == "ê²½ë ¥ì‚¬í•­":
                                # ê²½ë ¥ì‚¬í•­ í•„ë“œì¸ ê²½ìš° êµ¬ì¡°í™”ëœ í˜•íƒœë¡œ í‘œì‹œ
                                from services.llm_service import process_experience_field
                                experience_data = process_experience_field(field_info['content'])
                                if experience_data:
                                    # ê²½ë ¥ì‚¬í•­ ë°ì´í„°ë¥¼ JSON í˜•íƒœë¡œ í‘œì‹œ
                                    import json
                                    experience_json = json.dumps(experience_data, ensure_ascii=False, indent=2)
                                    field_data.append({
                                        "í•„ë“œëª…": field_name,
                                        "íƒ€ì…": field_info['type'],
                                        "ê°’": experience_json,
                                        "ì‹ ë¢°ë„": f"{field_info['confidence']:.2f}"
                                    })
                                else:
                                    field_data.append({
                                        "í•„ë“œëª…": field_name,
                                        "íƒ€ì…": field_info['type'],
                                        "ê°’": "ê²½ë ¥ì‚¬í•­ ì •ë³´ ì—†ìŒ",
                                        "ì‹ ë¢°ë„": f"{field_info['confidence']:.2f}"
                                    })
                            elif field_name == "ìê²©ì¦":
                                from services.llm_service import process_certificate_field
                                certificate_data = process_certificate_field(field_info['content'])
                                if certificate_data:
                                    # ìê²©ì¦ ë°ì´í„°ë¥¼ JSON í˜•íƒœë¡œ í‘œì‹œ
                                    import json
                                    certificate_json = json.dumps(certificate_data, ensure_ascii=False, indent=2)
                                    field_data.append({
                                        "í•„ë“œëª…": field_name,
                                        "íƒ€ì…": field_info['type'],
                                        "ê°’": certificate_json,
                                        "ì‹ ë¢°ë„": f"{field_info['confidence']:.2f}"
                                    })
                                else:
                                    field_data.append({
                                        "í•„ë“œëª…": field_name,
                                        "íƒ€ì…": field_info['type'],
                                        "ê°’": "ìê²©ì¦ ì •ë³´ ì—†ìŒ",
                                        "ì‹ ë¢°ë„": f"{field_info['confidence']:.2f}"
                                    })
                            elif field_name == "ìˆ˜ìƒê²½ë ¥":
                                # ìˆ˜ìƒê²½ë ¥ í•„ë“œì¸ ê²½ìš° êµ¬ì¡°í™”ëœ í˜•íƒœë¡œ í‘œì‹œ
                                from services.llm_service import process_award_field
                                award_data = process_award_field(field_info['content'])
                                if award_data:
                                    # ìˆ˜ìƒê²½ë ¥ ë°ì´í„°ë¥¼ JSON í˜•íƒœë¡œ í‘œì‹œ
                                    import json
                                    award_json = json.dumps(award_data, ensure_ascii=False, indent=2)
                                    field_data.append({
                                        "í•„ë“œëª…": field_name,
                                        "íƒ€ì…": field_info['type'],
                                        "ê°’": award_json,
                                        "ì‹ ë¢°ë„": f"{field_info['confidence']:.2f}"
                                    })
                                else:
                                    field_data.append({
                                        "í•„ë“œëª…": field_name,
                                        "íƒ€ì…": field_info['type'],
                                        "ê°’": "ìˆ˜ìƒê²½ë ¥ ì •ë³´ ì—†ìŒ",
                                        "ì‹ ë¢°ë„": f"{field_info['confidence']:.2f}"
                                    })
                            else:
                                field_data.append({
                                    "í•„ë“œëª…": field_name,
                                    "íƒ€ì…": field_info['type'],
                                    "ê°’": field_info['content'],
                                    "ì‹ ë¢°ë„": f"{field_info['confidence']:.2f}"
                                })
                        
                        # í•„ë“œ ë°ì´í„°ë¥¼ í…Œì´ë¸”ë¡œ í‘œì‹œ
                        if field_data:
                            df_fields = pd.DataFrame(field_data)
                            st.dataframe(df_fields, use_container_width=True)
                    
                    # ì±„ìš© ì í•©ì„± í‰ê°€
                    if job_files and selected_job:
                        job_text = extract_job_posting_text(selected_job, container_client)
                        if job_text:
                            st.markdown("---")
                            st.write("**ğŸ¯ ì±„ìš© ì í•©ì„± í‰ê°€:**")
                            
                            # ì´ë ¥ì„œ í•„ë“œ ë°ì´í„° ì¤€ë¹„ (ìš”ì•½ í…Œì´ë¸”ê³¼ ë™ì¼í•œ í•„ë“œë§Œ ì‚¬ìš©)
                            target_fields = ["í•™ë ¥ì‚¬í•­", "ê²½ë ¥ì‚¬í•­", "ìê²©ì¦", "ìˆ˜ìƒê²½ë ¥"]
                            resume_fields = {}
                            
                            for field_name in target_fields:
                                if field_name in fields:
                                    if field_name == "í•™ë ¥ì‚¬í•­":
                                        # í•™ë ¥ì‚¬í•­ ë°ì´í„°ë¥¼ êµ¬ì¡°í™”ëœ í˜•íƒœë¡œ ë³€í™˜
                                        from services.llm_service import process_education_field
                                        education_data = process_education_field(fields[field_name]['content'])
                                        resume_fields[field_name] = education_data
                                    elif field_name == "ê²½ë ¥ì‚¬í•­":
                                        # ê²½ë ¥ì‚¬í•­ ë°ì´í„°ë¥¼ êµ¬ì¡°í™”ëœ í˜•íƒœë¡œ ë³€í™˜
                                        from services.llm_service import process_experience_field
                                        experience_data = process_experience_field(fields[field_name]['content'])
                                        resume_fields[field_name] = experience_data
                                    elif field_name == "ìê²©ì¦":
                                        # ìê²©ì¦ ë°ì´í„°ë¥¼ êµ¬ì¡°í™”ëœ í˜•íƒœë¡œ ë³€í™˜
                                        from services.llm_service import process_certificate_field
                                        certificate_data = process_certificate_field(fields[field_name]['content'])
                                        resume_fields[field_name] = certificate_data
                                    elif field_name == "ìˆ˜ìƒê²½ë ¥":
                                        # ìˆ˜ìƒê²½ë ¥ ë°ì´í„°ë¥¼ êµ¬ì¡°í™”ëœ í˜•íƒœë¡œ ë³€í™˜
                                        from services.llm_service import process_award_field
                                        award_data = process_award_field(fields[field_name]['content'])
                                        resume_fields[field_name] = award_data
                                    else:
                                        resume_fields[field_name] = fields[field_name]['content']
                            
                            # í‰ê°€ ê¸°ì¤€ ë°ì´í„° JSON í˜•ì‹ìœ¼ë¡œ í‘œì‹œ
                            st.write("**ğŸ“‹ í‰ê°€ ê¸°ì¤€ ë°ì´í„°:**")
                            import json
                            
                            # ì¶”ì¶œí•  ì£¼ìš” í•„ë“œë“¤
                            target_fields = ["í•™ë ¥ì‚¬í•­", "ê²½ë ¥ì‚¬í•­", "ìê²©ì¦", "ìˆ˜ìƒê²½ë ¥"]
                            extracted_info = {}
                            
                            for field_name in target_fields:
                                if field_name in fields:
                                    field_info = fields[field_name]
                                    
                                    # í•™ë ¥ì‚¬í•­ í•„ë“œì¸ ê²½ìš° êµ¬ì¡°í™”ëœ í˜•íƒœë¡œ ë³€í™˜
                                    if field_name == "í•™ë ¥ì‚¬í•­":
                                        from services.llm_service import process_education_field
                                        education_data = process_education_field(field_info['content'])
                                        extracted_info[field_name] = education_data
                                    elif field_name == "ê²½ë ¥ì‚¬í•­":
                                        # ê²½ë ¥ì‚¬í•­ í•„ë“œì¸ ê²½ìš° êµ¬ì¡°í™”ëœ í˜•íƒœë¡œ ë³€í™˜
                                        from services.llm_service import process_experience_field
                                        experience_data = process_experience_field(field_info['content'])
                                        extracted_info[field_name] = experience_data
                                    elif field_name == "ìê²©ì¦":
                                        from services.llm_service import process_certificate_field
                                        certificate_data = process_certificate_field(field_info['content'])
                                        extracted_info[field_name] = certificate_data
                                    elif field_name == "ìˆ˜ìƒê²½ë ¥":
                                        # ìˆ˜ìƒê²½ë ¥ í•„ë“œì¸ ê²½ìš° êµ¬ì¡°í™”ëœ í˜•íƒœë¡œ ë³€í™˜
                                        from services.llm_service import process_award_field
                                        award_data = process_award_field(field_info['content'])
                                        extracted_info[field_name] = award_data
                                    else:
                                        extracted_info[field_name] = {
                                            "content": field_info['content'],
                                            "confidence": field_info['confidence'],
                                            "type": field_info['type']
                                        }
                            
                            # JSON í˜•íƒœë¡œ í‘œì‹œ
                            if extracted_info:
                                formatted_json = json.dumps(extracted_info, ensure_ascii=False, indent=2)
                                st.code(formatted_json, language="json")
                            else:
                                st.warning("í‰ê°€ ê¸°ì¤€ ë°ì´í„°ë¥¼ ì¶”ì¶œí•  ìˆ˜ ì—†ìŠµë‹ˆë‹¤.")
                            
                            # ì €ì¥ëœ ì í•©ì„± í‰ê°€ ê²°ê³¼ ì‚¬ìš©
                            fitness_evaluation = result.get("fitness_evaluation")
                            
                            if fitness_evaluation:
                                st.success("âœ… ì í•©ì„± í‰ê°€ ê²°ê³¼")
                                st.markdown("**ğŸ“Š í‰ê°€ ê²°ê³¼:**")
                                st.text_area(
                                    "í‰ê°€ ê²°ê³¼",
                                    value=fitness_evaluation,
                                    height=200,
                                    disabled=True,
                                    key=f"eval_result_{file_name}"
                                )
                            else:
                                st.warning("âš ï¸ ì í•©ì„± í‰ê°€ ê²°ê³¼ê°€ ì—†ìŠµë‹ˆë‹¤.")
    
    except Exception as e:
        st.error(f"íŒŒì¼ ëª©ë¡ ê°€ì ¸ì˜¤ê¸° ì‹¤íŒ¨: {str(e)}")
    
    # ì±—ë´‡ ê¸°ëŠ¥ í˜¸ì¶œ (í•­ìƒ í™”ë©´ í•˜ë‹¨ì— í‘œì‹œ)
    chat_with_llm()

if __name__ == "__main__":
    main() 